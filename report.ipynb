{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distributed training with NCCL\n",
    "In section two, we implemented distributed trainging using MPI communication API. This type of communication is very inconvenient, we need to turn the data into numpy, and use CPU to communicate. It doesn't take advantage of multiple GPUs. Therefore it is essential to use the NVIDIA Collective Communication Library(NCCL), which is developed by NVIDIA official.\n",
    "\n",
    "To enable direct communication between GPUs in NCCL, we should crreate a communicator first. In terms of concrete implementation, first we need to call the `ncclGetUniqueId()` function, it will return an ID, which will be used by all processees and threads to synchronize and understand they are part of the same communicator. Then we can use `ncclCommInitRank()` to create the communicator objects. The key issue is that we need to broadcast ID to all participating threads and processes using any CPU communication system. In the original MPI with CUDA program, we can call the CUDA-based MPI API to finish the broadcast. But in our project, we call CUDA program via Python, MPI is also based on Python. As a result, we can't use the CUDA-based MPI API but we can use the Python-based. \n",
    "\n",
    "Our solutions are as follows:\n",
    "\n",
    "1. Python program calls CUDA API, CUDA program gets the ID and returns it to Python.\n",
    "2. Python program calls Python-based MPI API to broadcast the ID.\n",
    "3. All processees and threads get the same ID, calls CUDA API to establish a connection.\n",
    "\n",
    "\n",
    "The relevant codes arre as follows:\n",
    "\n",
    "Python code:\n",
    "```\n",
    "def init():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank() # call MPI API to get world_size and rank\n",
    "    device = ndl.cuda(rank) # choose different GPUs\n",
    "    print(f'Use cuda: {rank}')\n",
    "\n",
    "    if rank==0:\n",
    "        vec = device.get_id() # get ID\n",
    "    else:\n",
    "        vec = None\n",
    "    vec = comm.bcast(vec, root=0) # broadcast ID\n",
    "\n",
    "    device.init_nccl(vec,rank,size) # establish a connection\n",
    "    return rank, size, device\n",
    "```\n",
    "\n",
    "CUDA code:\n",
    "```\n",
    "struct CudaCommAndStream{\n",
    "    int nRanks,localRank,myRank;\n",
    "    ncclUniqueId id;\n",
    "    ncclComm_t comm;\n",
    "    cudaStream_t s;\n",
    "}mess;\n",
    "void SetDevice(int id) # set different device\n",
    "{\n",
    "    mess.localRank=id;\n",
    "    cudaSetDevice(id);\n",
    "}\n",
    "std::vector<uint8_t> GetId()\n",
    "{\n",
    "    ncclGetUniqueId(&mess.id); # get id \n",
    "    auto vec = std::vector<uint8_t>(reinterpret_cast<uint8_t*>(&mess.id),reinterpret_cast<uint8_t*>(&mess.id) + NCCL_UNIQUE_ID_BYTES); # put id into vector\n",
    "    return vec;\n",
    "}\n",
    "\n",
    "void InitNccl(std::vector<uint8_t> vec,int rank,int size) \n",
    "{\n",
    "    mess.nRanks = size;\n",
    "    mess.myRank = rank;\n",
    "    std::memcpy(&mess.id, vec.data(), vec.size()); # change vector to id\n",
    "    ncclCommInitRank(&mess.comm, mess.nRanks, mess.id, mess.myRank); # establish a connection\n",
    "    cudaStreamCreate(&mess.s);\n",
    "}\n",
    "PYBIND11_MODULE(ndarray_backend_cuda, m) {\n",
    "    ...\n",
    "    m.def(\"set_device\", SetDevice);\n",
    "    m.def(\"get_id\", GetId);\n",
    "    m.def(\"init_nccl\", InitNccl);\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "Before running, we should install NCCL and modify CMakeLists.txt to find library path of NCCL in order to compile successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using nvidia-smi to find how many gpu available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  9 07:09:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:1A:00.0 Off |                  Off |\n",
      "| N/A   27C    P0    24W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "| N/A   25C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE...  Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| N/A   29C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE...  Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| N/A   27C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE...  Off  | 00000000:3E:00.0 Off |                  Off |\n",
      "| N/A   25C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE...  Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| N/A   50C    P0    40W / 250W |   1165MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE...  Off  | 00000000:42:00.0 Off |                  Off |\n",
      "| N/A   26C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mpiexec to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda: 2\n",
      "Use cuda: 3\n",
      "Use cuda: 7\n",
      "Use cuda: 4\n",
      "Use cuda: 5\n",
      "Use cuda: 1\n",
      "Use cuda: 0\n",
      "Use cuda: 6\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "partitioned dataset length: 6250\n",
      "0  correct: 0.33664  loss: 0  correct: [1.8683679]\n",
      "0  correct: 0  correct: 0.33888  loss: 0.33664  loss: 0  correct: 0.34624  loss: 0.3392  loss: 0  correct: [1.8647475]\n",
      "[1.8663205]\n",
      "0.33904  loss: [1.8584825]\n",
      "[1.8618884]\n",
      "0  correct: [1.8806661]\n",
      "0.3328  loss: Time: 43.870232820510864\n",
      "[1.8832192]\n",
      "0  correct: 0.33728  loss: [1.8480227]\n",
      "0.24752 [5.1031213]\n",
      "0.25008 [5.1413326]\n",
      "0.25008 0.25232 [5.1249537]\n",
      "[5.0528364]\n",
      "0.24896 [5.10206]\n",
      "0.2496 [4.9337025]\n",
      "0.24448 [5.0527062]\n",
      "0.25712 [5.2262936]\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -np {num_of_gpus} python apps/distribute_training.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare efficiency with simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda: 0\n",
      "partitioned dataset length: 50000\n",
      "0  correct: 0.34488  loss: [1.8502939]\n",
      "Time: 49.71820831298828\n",
      "0.2096 [4.8264384]\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -np 1 python apps/distribute_training.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "601b499b2199c856df16ec98313964189b457c31a1c25fec9d7f71bee01fcfcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
