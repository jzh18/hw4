{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distributed training with NCCL\n",
    "In section two, we implemented distributed trainging using MPI communication API. This type of communication is very inconvenient, we need to turn the data into numpy, and use CPU to communicate. It doesn't take advantage of multiple GPUs. Therefore it is essential to use the NVIDIA Collective Communication Library(NCCL), which is developed by NVIDIA official.\n",
    "\n",
    "To enable direct communication between GPUs in NCCL, we should crreate a communicator first. In terms of concrete implementation, first we need to call the `ncclGetUniqueId()` function, it will return an ID, which will be used by all processees and threads to synchronize and understand they are part of the same communicator. Then we can use `ncclCommInitRank()` to create the communicator objects. The key issue is that we need to broadcast ID to all participating threads and processes using any CPU communication system. In the original MPI with CUDA program, we can call the CUDA-based MPI API to finish the broadcast. But in our project, we call CUDA program via Python, MPI is also based on Python. As a result, we can't use the CUDA-based MPI API but we can use the Python-based. \n",
    "\n",
    "Our solutions are as follows:\n",
    "\n",
    "1. Python program calls CUDA API, CUDA program gets the ID and returns it to Python.\n",
    "2. Python program calls Python-based MPI API to broadcast the ID.\n",
    "3. All processees and threads get the same ID, calls CUDA API to establish a connection.\n",
    "\n",
    "\n",
    "The relevant codes arre as follows:\n",
    "\n",
    "Python code:\n",
    "```\n",
    "def init():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    size = comm.Get_size()\n",
    "    rank = comm.Get_rank() # call MPI API to get world_size and rank\n",
    "    device = ndl.cuda(rank) # choose different GPUs\n",
    "    print(f'Use cuda: {rank}')\n",
    "\n",
    "    if rank==0:\n",
    "        vec = device.get_id() # get ID\n",
    "    else:\n",
    "        vec = None\n",
    "    vec = comm.bcast(vec, root=0) # broadcast ID\n",
    "\n",
    "    device.init_nccl(vec,rank,size) # establish a connection\n",
    "    return rank, size, device\n",
    "```\n",
    "\n",
    "CUDA code:\n",
    "```\n",
    "struct CudaCommAndStream{\n",
    "    int nRanks,localRank,myRank;\n",
    "    ncclUniqueId id;\n",
    "    ncclComm_t comm;\n",
    "    cudaStream_t s;\n",
    "}mess;\n",
    "void SetDevice(int id) # set different device\n",
    "{\n",
    "    mess.localRank=id;\n",
    "    cudaSetDevice(id);\n",
    "}\n",
    "std::vector<uint8_t> GetId()\n",
    "{\n",
    "    ncclGetUniqueId(&mess.id); # get id \n",
    "    auto vec = std::vector<uint8_t>(reinterpret_cast<uint8_t*>(&mess.id),reinterpret_cast<uint8_t*>(&mess.id) + NCCL_UNIQUE_ID_BYTES); # put id into vector\n",
    "    return vec;\n",
    "}\n",
    "\n",
    "void InitNccl(std::vector<uint8_t> vec,int rank,int size) \n",
    "{\n",
    "    mess.nRanks = size;\n",
    "    mess.myRank = rank;\n",
    "    std::memcpy(&mess.id, vec.data(), vec.size()); # change vector to id\n",
    "    ncclCommInitRank(&mess.comm, mess.nRanks, mess.id, mess.myRank); # establish a connection\n",
    "    cudaStreamCreate(&mess.s);\n",
    "}\n",
    "PYBIND11_MODULE(ndarray_backend_cuda, m) {\n",
    "    ...\n",
    "    m.def(\"set_device\", SetDevice);\n",
    "    m.def(\"get_id\", GetId);\n",
    "    m.def(\"init_nccl\", InitNccl);\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10 (default, Feb 26 2021, 13:06:18) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b00e07dbc8c3725d3245e97766a20cd26fdf0d5fb68755f0602c6cabb01d8976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
